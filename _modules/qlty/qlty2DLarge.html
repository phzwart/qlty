

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>qlty.qlty2DLarge &mdash; qlty 1.3.5 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=03e43079" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />

  
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=4720776d"></script>
      <script src="../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            qlty
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../readme.html">qlty</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../usage.html">Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api.html">API Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../troubleshooting.html">Troubleshooting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../contributing.html">Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../authors.html">Credits</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../history.html">History</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">qlty</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">Module code</a></li>
      <li class="breadcrumb-item active">qlty.qlty2DLarge</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for qlty.qlty2DLarge</h1><div class="highlight"><pre>
<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">einops</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy.typing</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">npt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">zarr</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">qlty.base</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">compute_border_tensor_numpy</span><span class="p">,</span>
    <span class="n">compute_chunk_times</span><span class="p">,</span>
    <span class="n">compute_weight_matrix_numpy</span><span class="p">,</span>
    <span class="n">normalize_border</span><span class="p">,</span>
    <span class="n">validate_border_weight</span><span class="p">,</span>
<span class="p">)</span>


<div class="viewcode-block" id="LargeNCYXQuilt">
<a class="viewcode-back" href="../../api.html#qlty.qlty2DLarge.LargeNCYXQuilt">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">LargeNCYXQuilt</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This class allows one to split larger tensors into smaller ones that perhaps do fit into memory.</span>
<span class="sd">    This class is aimed at handling tensors of type (N, C, Y, X).</span>

<span class="sd">    This object is geared towards handling large datasets.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">filename</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">N</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">Y</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">X</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">window</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span>
        <span class="n">step</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span>
        <span class="n">border</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]],</span>
        <span class="n">border_weight</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This class allows one to split larger tensors into smaller ones that perhaps do fit into memory.</span>
<span class="sd">        This class is aimed at handling tensors of type (N, C, Y, X).</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        filename: the base filename for storage.</span>
<span class="sd">        Y : number of elements in the Y direction</span>
<span class="sd">        X : number of elements in the X direction</span>
<span class="sd">        window: The size of the sliding window, a tuple (Ysub, Xsub)</span>
<span class="sd">        step: The step size at which we want to sample the sliding window (Ystep, Xstep)</span>
<span class="sd">        border: Border pixels of the window we want to &#39;ignore&#39; or down weight when stitching things back</span>
<span class="sd">        border_weight: The weight for the border pixels, should be between 0 and 1. The default of 0.1 should be fine</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">filename</span> <span class="o">=</span> <span class="n">filename</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">N</span> <span class="o">=</span> <span class="n">N</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Y</span> <span class="o">=</span> <span class="n">Y</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">window</span> <span class="o">=</span> <span class="n">window</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">step</span> <span class="o">=</span> <span class="n">step</span>

        <span class="c1"># Normalize and validate border</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">border</span> <span class="o">=</span> <span class="n">normalize_border</span><span class="p">(</span><span class="n">border</span><span class="p">,</span> <span class="n">ndim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">border_weight</span> <span class="o">=</span> <span class="n">validate_border_weight</span><span class="p">(</span><span class="n">border_weight</span><span class="p">)</span>

        <span class="c1"># Compute chunk times</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nY</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">nX</span> <span class="o">=</span> <span class="n">compute_chunk_times</span><span class="p">(</span>
            <span class="n">dimension_sizes</span><span class="o">=</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">X</span><span class="p">),</span> <span class="n">window</span><span class="o">=</span><span class="n">window</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="n">step</span>
        <span class="p">)</span>

        <span class="c1"># Compute weight matrix (as torch tensor for compatibility)</span>
        <span class="n">weight_np</span> <span class="o">=</span> <span class="n">compute_weight_matrix_numpy</span><span class="p">(</span>
            <span class="n">window</span><span class="o">=</span><span class="n">window</span><span class="p">,</span> <span class="n">border</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">border</span><span class="p">,</span> <span class="n">border_weight</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">border_weight</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">weight_np</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">N_chunks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">N</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">nY</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">nX</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mean</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norma</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">chunkerator</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">N_chunks</span><span class="p">))</span>

<div class="viewcode-block" id="LargeNCYXQuilt.border_tensor">
<a class="viewcode-back" href="../../api.html#qlty.qlty2DLarge.LargeNCYXQuilt.border_tensor">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">border_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">npt</span><span class="o">.</span><span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute border tensor indicating valid (non-border) regions.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">compute_border_tensor_numpy</span><span class="p">(</span><span class="n">window</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">window</span><span class="p">,</span> <span class="n">border</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">border</span><span class="p">)</span></div>


<div class="viewcode-block" id="LargeNCYXQuilt.get_times">
<a class="viewcode-back" href="../../api.html#qlty.qlty2DLarge.LargeNCYXQuilt.get_times">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">get_times</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the number of chunks along Y and X dimensions, ensuring the last chunk</span>
<span class="sd">        is included by adjusting the starting points.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">compute_chunk_times</span><span class="p">(</span>
            <span class="n">dimension_sizes</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">),</span> <span class="n">window</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">window</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">step</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="LargeNCYXQuilt.unstitch_and_clean_sparse_data_pair">
<a class="viewcode-back" href="../../api.html#qlty.qlty2DLarge.LargeNCYXQuilt.unstitch_and_clean_sparse_data_pair">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">unstitch_and_clean_sparse_data_pair</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">tensor_in</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">tensor_out</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">missing_label</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">List</span><span class="p">],</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">List</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Split input and output tensors into patches, filtering out patches with no valid data.</span>

<span class="sd">        This method combines unstitching with sparse data filtering. It:</span>
<span class="sd">        1. Splits both tensors into patches</span>
<span class="sd">        2. Marks border regions as missing</span>
<span class="sd">        3. Filters out patches that contain only missing labels</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        tensor_in : torch.Tensor</span>
<span class="sd">            Input tensor of shape (N, C, Y, X). The tensor going into the network.</span>
<span class="sd">        tensor_out : torch.Tensor</span>
<span class="sd">            Output tensor of shape (N, C, Y, X) or (N, Y, X). The target tensor.</span>
<span class="sd">            Missing/invalid data should be marked with `missing_label`.</span>
<span class="sd">        missing_label : Union[int, float]</span>
<span class="sd">            Label value that indicates missing/invalid data. Patches containing only</span>
<span class="sd">            this value (including border regions) will be filtered out.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Tuple[Union[torch.Tensor, List], Union[torch.Tensor, List]]</span>
<span class="sd">            A tuple of (input_patches, output_patches). If no valid patches are found,</span>
<span class="sd">            returns empty lists. Otherwise returns torch.Tensor objects.</span>

<span class="sd">            - input_patches: Shape (M, C, window[0], window[1]) where M &lt;= N * nY * nX</span>
<span class="sd">            - output_patches: Shape (M, C, window[0], window[1]) or (M, window[0], window[1])</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        - Border regions are automatically marked as missing in the output patches</span>
<span class="sd">        - Only patches with at least one non-missing label in the valid (non-border) region are kept</span>
<span class="sd">        - This is useful for training with sparse annotations where most of the image is unlabeled</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; quilt = LargeNCYXQuilt(&quot;data&quot;, N=10, Y=128, X=128,</span>
<span class="sd">        ...                        window=(32, 32), step=(16, 16), border=(5, 5))</span>
<span class="sd">        &gt;&gt;&gt; input_data = torch.randn(10, 3, 128, 128)</span>
<span class="sd">        &gt;&gt;&gt; labels = torch.ones(10, 128, 128) * (-1)  # All missing</span>
<span class="sd">        &gt;&gt;&gt; labels[:, 20:108, 20:108] = 1.0            # Some valid data</span>
<span class="sd">        &gt;&gt;&gt; inp_patches, lbl_patches = quilt.unstitch_and_clean_sparse_data_pair(</span>
<span class="sd">        ...     input_data, labels, missing_label=-1</span>
<span class="sd">        ... )</span>
<span class="sd">        &gt;&gt;&gt; print(f&quot;Valid patches: {len(inp_patches) if isinstance(inp_patches, list) else inp_patches.shape[0]}&quot;)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">rearranged</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">tensor_out</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
            <span class="n">tensor_out</span> <span class="o">=</span> <span class="n">tensor_out</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">rearranged</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">tensor_out</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">4</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">tensor_in</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">4</span>
        <span class="k">assert</span> <span class="n">tensor_in</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">tensor_out</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="n">unstitched_in</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">unstitched_out</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">modsel</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">border_tensor</span><span class="p">()</span>
        <span class="n">modsel</span> <span class="o">=</span> <span class="n">modsel</span> <span class="o">&lt;</span> <span class="mf">0.5</span>

        <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">N_chunks</span><span class="p">):</span>
            <span class="n">out_chunk</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">unstitch</span><span class="p">(</span><span class="n">tensor_out</span><span class="p">,</span> <span class="n">ii</span><span class="p">)</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
            <span class="n">out_chunk</span><span class="p">[:,</span> <span class="n">modsel</span><span class="p">]</span> <span class="o">=</span> <span class="n">missing_label</span>
            <span class="n">NN</span> <span class="o">=</span> <span class="n">out_chunk</span><span class="o">.</span><span class="n">nelement</span><span class="p">()</span>
            <span class="n">not_present</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">out_chunk</span> <span class="o">==</span> <span class="n">missing_label</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">not_present</span> <span class="o">!=</span> <span class="n">NN</span><span class="p">:</span>
                <span class="n">unstitched_in</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">unstitch</span><span class="p">(</span><span class="n">tensor_in</span><span class="p">,</span> <span class="n">ii</span><span class="p">))</span>
                <span class="n">unstitched_out</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">out_chunk</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">unstitched_in</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">unstitched_in</span> <span class="o">=</span> <span class="n">einops</span><span class="o">.</span><span class="n">rearrange</span><span class="p">(</span><span class="n">unstitched_in</span><span class="p">,</span> <span class="s2">&quot;N C Y X -&gt; N C Y X&quot;</span><span class="p">)</span>
            <span class="n">unstitched_out</span> <span class="o">=</span> <span class="n">einops</span><span class="o">.</span><span class="n">rearrange</span><span class="p">(</span><span class="n">unstitched_out</span><span class="p">,</span> <span class="s2">&quot;N C Y X -&gt; N C Y X&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">rearranged</span><span class="p">:</span>
                <span class="k">assert</span> <span class="n">unstitched_out</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span>
                <span class="n">unstitched_out</span> <span class="o">=</span> <span class="n">unstitched_out</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">unstitched_in</span><span class="p">,</span> <span class="n">unstitched_out</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">[],</span> <span class="p">[]</span></div>


<div class="viewcode-block" id="LargeNCYXQuilt.unstitch">
<a class="viewcode-back" href="../../api.html#qlty.qlty2DLarge.LargeNCYXQuilt.unstitch">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">unstitch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensor</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">index</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Extract a single patch from a tensor by index.</span>

<span class="sd">        This method is used internally by `unstitch_next()` but can also be called</span>
<span class="sd">        directly if you know the patch index.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        tensor : torch.Tensor</span>
<span class="sd">            Input tensor of shape (N, C, Y, X) where:</span>
<span class="sd">            - N: Number of images</span>
<span class="sd">            - C: Number of channels</span>
<span class="sd">            - Y, X: Must match self.Y and self.X</span>
<span class="sd">        index : int</span>
<span class="sd">            Linear index of the patch to extract. Must be in range [0, N_chunks).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.Tensor</span>
<span class="sd">            Single patch of shape (C, window[0], window[1])</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; quilt = LargeNCYXQuilt(&quot;data&quot;, N=10, Y=128, X=128,</span>
<span class="sd">        ...                        window=(32, 32), step=(16, 16))</span>
<span class="sd">        &gt;&gt;&gt; data = torch.randn(10, 3, 128, 128)</span>
<span class="sd">        &gt;&gt;&gt; patch = quilt.unstitch(data, index=0)</span>
<span class="sd">        &gt;&gt;&gt; print(patch.shape)  # (3, 32, 32)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">X</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">shape</span>

        <span class="n">out_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">nY</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">nX</span><span class="p">)</span>
        <span class="n">n</span><span class="p">,</span> <span class="n">yy</span><span class="p">,</span> <span class="n">xx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unravel_index</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">out_shape</span><span class="p">)</span>

        <span class="c1"># Adjust the starting point for the last chunk in each dimension</span>
        <span class="n">start_y</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">yy</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">step</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Y</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">window</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">start_x</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">xx</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">step</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">X</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">window</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

        <span class="n">stop_y</span> <span class="o">=</span> <span class="n">start_y</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">window</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">stop_x</span> <span class="o">=</span> <span class="n">start_x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">window</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

        <span class="n">patch</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">[</span><span class="n">n</span><span class="p">,</span> <span class="p">:,</span> <span class="n">start_y</span><span class="p">:</span><span class="n">stop_y</span><span class="p">,</span> <span class="n">start_x</span><span class="p">:</span><span class="n">stop_x</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">patch</span></div>


<div class="viewcode-block" id="LargeNCYXQuilt.stitch">
<a class="viewcode-back" href="../../api.html#qlty.qlty2DLarge.LargeNCYXQuilt.stitch">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">stitch</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">patch</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">index_flat</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">patch_var</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">C</span> <span class="o">=</span> <span class="n">patch</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Initialization code remains the same...</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mean</span> <span class="o">=</span> <span class="n">zarr</span><span class="o">.</span><span class="n">open</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">filename</span> <span class="o">+</span> <span class="s2">&quot;_mean_cache.zarr&quot;</span><span class="p">,</span>
                <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">),</span>
                <span class="n">chunks</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">window</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">window</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span>
                <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;w&quot;</span><span class="p">,</span>
                <span class="n">fill_value</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">std</span> <span class="o">=</span> <span class="n">zarr</span><span class="o">.</span><span class="n">open</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">filename</span> <span class="o">+</span> <span class="s2">&quot;_std_cache.zarr&quot;</span><span class="p">,</span>
                <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">),</span>
                <span class="n">chunks</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">window</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">window</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span>
                <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;w&quot;</span><span class="p">,</span>
                <span class="n">fill_value</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">norma</span> <span class="o">=</span> <span class="n">zarr</span><span class="o">.</span><span class="n">open</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">filename</span> <span class="o">+</span> <span class="s2">&quot;_norma_cache.zarr&quot;</span><span class="p">,</span>
                <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">),</span>
                <span class="n">chunks</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">window</span><span class="p">,</span>
                <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;w&quot;</span><span class="p">,</span>
                <span class="n">fill_value</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="n">screen_shape</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">N</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">nY</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">nX</span><span class="p">)</span>
        <span class="n">n</span><span class="p">,</span> <span class="n">yy</span><span class="p">,</span> <span class="n">xx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unravel_index</span><span class="p">(</span><span class="n">index_flat</span><span class="p">,</span> <span class="n">screen_shape</span><span class="p">)</span>
        <span class="c1"># Adjust the starting point for the last chunk in each dimension</span>
        <span class="n">start_y</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">yy</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">step</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">Y</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">window</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">start_x</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">xx</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">step</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">window</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

        <span class="n">stop_y</span> <span class="o">=</span> <span class="n">start_y</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">window</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">stop_x</span> <span class="o">=</span> <span class="n">start_x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">window</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

        <span class="c1"># Update the mean, std, and norma arrays</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mean</span><span class="p">[</span><span class="n">n</span> <span class="p">:</span> <span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="p">:,</span> <span class="n">start_y</span><span class="p">:</span><span class="n">stop_y</span><span class="p">,</span> <span class="n">start_x</span><span class="p">:</span><span class="n">stop_x</span><span class="p">]</span> <span class="o">+=</span> <span class="p">(</span>
            <span class="n">patch</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">patch_var</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">std</span><span class="p">[</span><span class="n">n</span> <span class="p">:</span> <span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="p">:,</span> <span class="n">start_y</span><span class="p">:</span><span class="n">stop_y</span><span class="p">,</span> <span class="n">start_x</span><span class="p">:</span><span class="n">stop_x</span><span class="p">]</span> <span class="o">+=</span> <span class="p">(</span>
                <span class="n">patch_var</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">n</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">norma</span><span class="p">[</span><span class="n">start_y</span><span class="p">:</span><span class="n">stop_y</span><span class="p">,</span> <span class="n">start_x</span><span class="p">:</span><span class="n">stop_x</span><span class="p">]</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span></div>


<div class="viewcode-block" id="LargeNCYXQuilt.unstitch_next">
<a class="viewcode-back" href="../../api.html#qlty.qlty2DLarge.LargeNCYXQuilt.unstitch_next">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">unstitch_next</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensor</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the next patch in sequence (generator-like interface).</span>

<span class="sd">        This method maintains an internal iterator and returns the next patch</span>
<span class="sd">        each time it&#39;s called. Useful for processing large datasets chunk by chunk.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        tensor : torch.Tensor</span>
<span class="sd">            Input tensor of shape (N, C, Y, X) where N matches self.N</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Tuple[int, torch.Tensor]</span>
<span class="sd">            A tuple of (index, patch) where:</span>
<span class="sd">            - index: Linear index of the patch (0 to N_chunks-1)</span>
<span class="sd">            - patch: Patch tensor of shape (C, window[0], window[1])</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        The iterator resets after reaching the end. To process all patches::</span>

<span class="sd">            for i in range(quilt.N_chunks):</span>
<span class="sd">                index, patch = quilt.unstitch_next(data)</span>
<span class="sd">                # Process patch...</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; quilt = LargeNCYXQuilt(&quot;data&quot;, N=10, Y=128, X=128,</span>
<span class="sd">        ...                        window=(32, 32), step=(16, 16))</span>
<span class="sd">        &gt;&gt;&gt; data = torch.randn(10, 3, 128, 128)</span>
<span class="sd">        &gt;&gt;&gt; for i in range(quilt.N_chunks):</span>
<span class="sd">        ...     idx, patch = quilt.unstitch_next(data)</span>
<span class="sd">        ...     processed = model(patch.unsqueeze(0))</span>
<span class="sd">        ...     quilt.stitch(processed, idx)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">this_ind</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">chunkerator</span><span class="p">)</span>
        <span class="n">tmp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">unstitch</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">this_ind</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">this_ind</span><span class="p">,</span> <span class="n">tmp</span></div>


<div class="viewcode-block" id="LargeNCYXQuilt.return_mean">
<a class="viewcode-back" href="../../api.html#qlty.qlty2DLarge.LargeNCYXQuilt.return_mean">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">return_mean</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">std</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">normalize</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">eps</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-8</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span>
        <span class="n">npt</span><span class="o">.</span><span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">],</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">npt</span><span class="o">.</span><span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">],</span> <span class="n">npt</span><span class="o">.</span><span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">]]</span>
    <span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute and return the final stitched result.</span>

<span class="sd">        After calling `stitch()` for all patches, this method computes the final</span>
<span class="sd">        averaged result. The result is normalized by the weight matrix to account</span>
<span class="sd">        for overlapping regions and border downweighting.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        std : bool, optional</span>
<span class="sd">            Whether to compute and return the standard deviation. Requires that</span>
<span class="sd">            `patch_var` was provided to `stitch()` calls. Default is False.</span>
<span class="sd">        normalize : bool, optional</span>
<span class="sd">            Whether to normalize the result so that values sum to 1.0 along the</span>
<span class="sd">            channel dimension. Useful for probability distributions. Default is False.</span>
<span class="sd">        eps : float, optional</span>
<span class="sd">            Small epsilon value to prevent division by zero. Default is 1e-8.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Union[npt.NDArray, Tuple[npt.NDArray, npt.NDArray]]</span>
<span class="sd">            If std=False: Returns mean array of shape (N, C, Y, X)</span>
<span class="sd">            If std=True: Returns tuple (mean, std) where both have shape (N, C, Y, X)</span>

<span class="sd">            The result is a NumPy array (stored as Zarr array on disk).</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        - This method uses Dask for parallel processing of the Zarr arrays</span>
<span class="sd">        - Results are saved to disk as Zarr arrays (filename + &#39;_mean.zarr&#39; and &#39;_std.zarr&#39;)</span>
<span class="sd">        - The computation happens lazily and is only executed when needed</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; quilt = LargeNCYXQuilt(&quot;data&quot;, N=10, Y=128, X=128,</span>
<span class="sd">        ...                        window=(32, 32), step=(16, 16))</span>
<span class="sd">        &gt;&gt;&gt; # ... process all patches with quilt.stitch() ...</span>
<span class="sd">        &gt;&gt;&gt; mean = quilt.return_mean()</span>
<span class="sd">        &gt;&gt;&gt; mean, std = quilt.return_mean(std=True)</span>
<span class="sd">        &gt;&gt;&gt; print(f&quot;Mean shape: {mean.shape}&quot;)  # (10, C, 128, 128)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">dask.array</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">da</span>

        <span class="c1"># Convert Zarr arrays to Dask arrays for parallel processing</span>
        <span class="n">mean_dask</span> <span class="o">=</span> <span class="n">da</span><span class="o">.</span><span class="n">from_zarr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mean</span><span class="p">)</span>
        <span class="n">norma_dask</span> <span class="o">=</span> <span class="n">da</span><span class="o">.</span><span class="n">from_zarr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">norma</span><span class="p">)</span> <span class="o">+</span> <span class="n">eps</span>
        <span class="n">norma_dask</span> <span class="o">=</span> <span class="n">da</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">norma_dask</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">norma_dask</span> <span class="o">=</span> <span class="n">da</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">norma_dask</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">std_dask</span> <span class="o">=</span> <span class="n">da</span><span class="o">.</span><span class="n">from_zarr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">std</span><span class="p">)</span> <span class="k">if</span> <span class="n">std</span> <span class="k">else</span> <span class="kc">None</span>

        <span class="c1"># Compute mean and std using Dask</span>
        <span class="n">mean_accumulated</span> <span class="o">=</span> <span class="n">mean_dask</span> <span class="o">/</span> <span class="n">norma_dask</span>
        <span class="k">if</span> <span class="n">std</span><span class="p">:</span>
            <span class="n">std_accumulated</span> <span class="o">=</span> <span class="n">da</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">da</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">std_dask</span> <span class="o">/</span> <span class="n">norma_dask</span><span class="p">))</span>

        <span class="c1"># Renormalize if required</span>
        <span class="k">if</span> <span class="n">normalize</span><span class="p">:</span>
            <span class="n">norm</span> <span class="o">=</span> <span class="n">da</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">mean_accumulated</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">mean_accumulated</span> <span class="o">/=</span> <span class="n">norm</span>
            <span class="k">if</span> <span class="n">std</span><span class="p">:</span>
                <span class="n">std_accumulated</span> <span class="o">/=</span> <span class="n">norm</span>

        <span class="c1"># Define file paths for Zarr arrays</span>
        <span class="n">mean_zarr_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">filename</span> <span class="o">+</span> <span class="s2">&quot;_mean.zarr&quot;</span>
        <span class="n">std_zarr_path</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">filename</span> <span class="o">+</span> <span class="s2">&quot;_std.zarr&quot;</span><span class="p">)</span> <span class="k">if</span> <span class="n">std</span> <span class="k">else</span> <span class="kc">None</span>

        <span class="c1"># Store the result into Zarr arrays on disk</span>
        <span class="n">mean_zarr</span> <span class="o">=</span> <span class="n">mean_accumulated</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
        <span class="n">zarr</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">mean_zarr_path</span><span class="p">,</span> <span class="n">mean_zarr</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">std</span><span class="p">:</span>
            <span class="n">std_zarr</span> <span class="o">=</span> <span class="n">std_accumulated</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
            <span class="n">zarr</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">std_zarr_path</span><span class="p">,</span> <span class="n">std_zarr</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">mean_zarr</span><span class="p">,</span> <span class="n">std_zarr</span>
        <span class="k">return</span> <span class="n">mean_zarr</span></div>
</div>

</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, Petrus H. Zwart.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>